What is congestion?
When traffic exceeds the network’s capacity. Maximum bandwidth is not always you get. Lots of things are shared. Too many conversation in a link the buffers are going to fill up and routers will going to be dropped. Before the fill up, the packets are also going to be delayed (waiting for the buffer to be cleared). Congestion is that the packet is delayed or dropped beyond the acceptable service quality. That’s when there is the congestion. Congestion includes both over delayed and drops. 

Goodput: the rate at which useful packets are delivered by the network, not dropped or retransmitted duplicate packets.  

The congestion happens really quick after it reached the point of the onset of congestion since it reaches the point burst, which is too many packets in the short period of time and with longer period of time with no packet or fewer packets. Internet traffic is actually bursty. At some point it has more packets to send, and at some point it has fewer packets to send. TCP traffic is self similar or fractal, because it is bursty. Constant bitrates expected when watching Netflix. But is it?   CThe congestion happens really quick after it reached the point of the onset of congestion since it reaches the point burst, which is too many packets in the short period of time and with longer period of time with no packet or fewer packets. Internet traffic is actually bursty. At some point it has more packets to send, and at some point it has fewer packets to send. TCP traffic is self similar or fractal, because it is bursty. Constant bitrate is expected when watching. I frame, B frame, and P frame. B frames are extremely small, P frame is mid size and I frame is huge as jpeg files. Usually sends in IPPB sequence or so, contributing the congestion collapse. Suddenly it starts dropping package and buffer gets full. What makes this worse is the retransmission done by the TCP. This makes congestion much worse. If the packets are delayed too long, the RTO in TCP, is going to assume the package lost. Send the packet again. Worsening the congestion. Making traffic more and more. There needs to be a way to control the congestion.

Vanilla congestion control: TCP uses the congestion window, to control the transmission speed according to the network’s capacity. This congestion window is going to dictate how much TCP is allowed to send. The network implicitly telling the TCP how much you can actually send. What happens is that TCP uses RTO timeout or duplication detection to detect any sort of problems during the transmission. First RTO timeout is the sign for the TCP to panic. Other signs, when ACK are coming, but as the sender is the sending keeps ACK number keeps coming. How can the second sign happen? Receiver is supposed to send what they are expecting. The reason is that segment is lost during the transmission. After then, the receiver although receiving the new packets, reminds sender to send the missing packet. If the receiver keeps sending the same ACK number, means the packet hasn’t arrived to the receiver. Assuming the packet was lost. Note that the congestion window is in addition to flow control window. TCP must adhere to both so the smaller window determines the speed. These windows run in parallel, and TCP always go with the smaller one. Before we actually go into the panic, TCP uses a slow start. It first sends the typically one, no more than 4 segments. TCP then increases the congestion window with every acknowledgement. ![[Pasted image 20250317204124.png]]
In the figure, notice the time gap between consecutive received segments in each RTT round cwnd=2, this is because in some part of the network, the network’s capacity is slower than the part on which the sender resides, so segments are going through the slower. Note that the sender receives two acknowledgements 3,4 in a time gap. This is to calculate how congested it is.  BPD? Taking same as RTT, means it is similar to the maximum size the window should have. At cwnd=4 it is almost the same size as the RTT. Over than that it will cause the congestion. We can imagine cwnd = 7 causes the problem. 

 
![[Pasted image 20250317211236.png]]
Initially set to control window size. After teaching the threshold. What does this additive increase mean? You only receive the cwnd by one after all previous segments are acknowledged. Note for the cwnd=3. It is clear that it is waiting for both of the packets to be acknowledged. 

Combining slow start and additive increase. 
![[Pasted image 20250317212600.png]]
At the beginning the threshold is the window size itself, at the beginning the dots are the size of the congestion window, increasing. After first you can see it increased to 2. Then you receive 2 acknowledgements back, now the window size is 4. It increases exponentially, reaching the threshold we have set. Once it reaches the threshold, now it moves from slow start to additive increase. The congestion window gets increased only by one. At this point, the congestion window is 32. Sender is going to send 32 segments, after receiving all the acknowledgements, it increases by one. Encountering packet loss! Drop the rate all way down to the one, decrease the previous threshold to half the maximum value before the packet loss, 40 → 20. When things were half, it was for sure it was working fine. Now it starts again. It increases the congestion window to 2, 4, …. Then it hits the threshold and turns into the additive increase mode. This is how congestion control works. If the receiver sets the sliding window smaller than the threshold, it will follow the lower window size. 

This might be over reacting, starting from 1 again. This was the reason why multimedia services used UDP over TCP in the early era. For streaming, presentational application uses TCP now, but conversational like Zoom still uses UDP. 

What is the way to find out the packet was lost? RTO timeout (not getting ack). Or if duplicate ack numbers. When package beyond the lost packet arrive at the receiver, receiver sends ACK but with the same number as the last acknowledged packet. This could happen before the RTO timeout. From this, the sender can infer which packet is lost, and it can retransmit without waiting for timeout. This is known as fast retransmission. The last method is by using selective ACK, which is SACK in TCP’s option field. Sender can now easily know which packet is lost. In this one, receiver can explicitly send to the sender which packet did or didn’t arrive. Might be faster than the duplicate ACK numbers, since first, sender should wait to get the duplicate ACK, and sender should calculate which packet was lost.
![[Pasted image 20250318081006.png]]
Sender sends packets 0,1,2,3, and 4 at the same time initially. The receiver receives packet 0 and asks for the next sequenced packet, by sending ACK-1. Sender gets the ACK-1 and sends packet-5 to maintain cwnd=5. Packet 1 gets dropped. The receiver gets packet 2. Sends packet 6 to maintain cwnd=5. Now packets are out of order. It asks for packet 1 by sending ACK-1 and creates a SACK block for the next required packet. The ack field will keep on sending duplicate numbers. The receiver sends ACK-1 and SACK 2-3. ACK 1 means the receiver is asking for packet 1. Sack 2-3 means the receiver got packet 2 and asked for packet 3. 
Packet 3 also got dropped. Sends packet-7 to maintain cwnd=5. Receiver buffer loss like [0,2,4]. So there are two holes in the buffer. The receiver sends ACK-1 and SACK 2-3, 4-5. Means receiver has got packet 2&4 and asking for packet 3 & 5. Also sends 2nd duplicate ack 1. 

In total, 3 ranges like that is allowed. ![[Pasted image 20250318082001.png]]
This is in class example. Here, in SACK, there are only successfully arrived packets. It is easy to find out which packets are missing. 

Too slow to set the cwnd =1. In the diagram of the example, it is visible that the half of the cwnd was working without any problem. The way to solve this problem is the fast recovery. Set the cwnd to the half value, but go up additively instead. The idea is to go exponentially at the beginning, once reaching threshold going up additively, and then cut the cwnd into half when the packet lost, and go up additively. ![[Pasted image 20250318082744.png]]

The content so fat is about how to control the congestion. There are ways to prevent it beforehand. 

Active Queue Management: queue is buffer in the router. Now router is engaged, not only the TCP protocol. Tell tcp that there is going to be the congestion before it happens. TCP congestion control is reaction towards the congestion, and AQM is the prevention of the congestion. Usually involves the router purposely discarding the packets before the buffer is entirely full. Why would this reduce traffic? : if the router drops the packet, one of the packet loss detection mechanism would work, TCP is going to react, forcing TCP to back off. So the congestion actually never occurs. Doesn’t work for TCP. This is shown to improve the performance compared to the dropping the packets only then the buffer is full. Random early detection is one example of AQM.

Random Early Detection: traffic surges fill buffers and cause discards at routers. For TCP discard means to enter slow start, reducing load. However, the discraded packets still need to be retransmitted. This causes global synchronization. Traffic bursts fill router queues, so packets are lost again. Many TCP connections enter slow start again, traffic drops so network is underutilized again, connections leave slow start at some time causing bursts and congestion again. 
Bigger buffers will not help. Just a longer time for the delay to happen. Therefore, RED tries to anticipate the onset of congestion and tell some connections to slow down. 
![[Pasted image 20250318085109.png]]
Burst of traffic, packets move and go quick, looking at one single instance is not a good indication of time series. Weighted: older loses the importance, the newer gets more weighted. And this weighting is done exponentially in RED. If average is lower than the minimum threshold, no problem. If average is bigger than maximum threshold, then drops the packet. If they are between minimum and maximum threshold, calculate drop probability Pa, and with that probability, drop or save the packet in the buffer. As the buffer is getting full, the Pa gets higher and higher. 
![[Pasted image 20250318085706.png]]
![[Pasted image 20250318090103.png]]

Why drop the packet? Notify the sender that we are reaching the limit. Source quench: only goes to the sender from the router. Deprecated. ICMP mesgs are blocked in many cases. Now having better technology such as Explicit Congestion Notification. 

Explicit congestion notification: the goal is to achieve RED result without dropping any packets. For ECN to work, the sender, receiver and congested routes in between must support ECN. Both IP and TCP must be ECN compliant. ECN router will proactively monitor its buffer level, similar to RED, but instead of dropping the packet, it marks the packet with the Congestion Encountered (CE). 
![[Pasted image 20250318091027.png]]
How does the router mark the CE?
![[Pasted image 20250318091043.png]]
IP header. In the 16 bits Differentiated services, used for QoS (ToS). The last two bits are used for ECN. The first 3 are set by the end hosts, both 10 and 01 are treated the same with the router, and only set to them when both end hosts know what ECN is. This happens in the three way handshake. They check if they both support the ECN, and turn the bits on. The router sets it to 11. 
![[Pasted image 20250318091507.png]]
Notifying the ECN is done with TCP. CWR, which is congestion window reduce bit, ECE with explicit congestion echo, receiver keeps setting the ECE bit for all future segments to the sender, until the receiver gets a segment from the sender in which the CWR bit is set. The receiver then stops the ECE bit, until it receives another marked packet with CE. Router is now informing to the receiver there is congestion, with CE set, then receiver sends the ECE bit in the TCP header. Then the sender conducts the packet loss situation and then set CWR bit. 